{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ray.tune.suggest'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tune\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtune\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschedulers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ASHAScheduler\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtune\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msuggest\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbayesopt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BayesOptSearch\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m f1_score\n\u001b[1;32m     16\u001b[0m load_dotenv\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ray.tune.suggest'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.suggest.bayesopt import BayesOptSearch\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming feature_df and targets_df are already defined\n",
    "data_dir = os.getenv(\"DATA\")\n",
    "minmax_df = pd.read_csv(Path(data_dir) / \"minmax_dataset.csv\")\n",
    "targets_df = pd.read_csv(Path(data_dir) / \"target.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = minmax_df.sample(n=50000)\n",
    "ids = X.id\n",
    "y = targets_df[targets_df.id.isin(ids)].drop(columns=[\"id\"]).values.reshape(-1)\n",
    "X = X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-30 12:18:44,996\tWARNING services.py:2022 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67096576 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=10.24gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2024-09-30 12:18:45,089\tINFO worker.py:1777 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    }
   ],
   "source": [
    "X_id = ray.put(X)\n",
    "y_id = ray.put(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GPU': 1.0,\n",
       " 'memory': 23334279373.0,\n",
       " 'accelerator_type:G': 1.0,\n",
       " 'object_store_memory': 10000000000.0,\n",
       " 'CPU': 12.0,\n",
       " 'node:__internal_head__': 1.0,\n",
       " 'node:172.17.0.2': 1.0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.available_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluators import evaluate_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-30 12:18:46,922\tINFO worker.py:1619 -- Calling ray.init() again after it has already been called.\n",
      "2024-09-30 12:18:46,924\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-09-30 12:37:09</td></tr>\n",
       "<tr><td>Running for: </td><td>00:18:22.86        </td></tr>\n",
       "<tr><td>Memory:      </td><td>23.9/47.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=36<br>Bracket: Iter 64.000: None | Iter 16.000: None | Iter 4.000: None | Iter 1.000: 0.000809268748013036<br>Logical resource usage: 1.0/12 CPUs, 0.125/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status    </th><th>loc             </th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  units_1</th><th style=\"text-align: right;\">  units_2</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   f1_score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_247ab_00000</td><td>TERMINATED</td><td>172.17.0.2:46022</td><td style=\"text-align: right;\">    0.000469946</td><td style=\"text-align: right;\">       46</td><td style=\"text-align: right;\">       50</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         155.814</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00001</td><td>TERMINATED</td><td>172.17.0.2:46023</td><td style=\"text-align: right;\">    0.00442509 </td><td style=\"text-align: right;\">      111</td><td style=\"text-align: right;\">       88</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         185.498</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00002</td><td>TERMINATED</td><td>172.17.0.2:46024</td><td style=\"text-align: right;\">    0.000913068</td><td style=\"text-align: right;\">       35</td><td style=\"text-align: right;\">      124</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         151.302</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00003</td><td>TERMINATED</td><td>172.17.0.2:46026</td><td style=\"text-align: right;\">    0.000246856</td><td style=\"text-align: right;\">       54</td><td style=\"text-align: right;\">      126</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         149.368</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00004</td><td>TERMINATED</td><td>172.17.0.2:46025</td><td style=\"text-align: right;\">    0.00239071 </td><td style=\"text-align: right;\">       65</td><td style=\"text-align: right;\">      117</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         176.511</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00005</td><td>TERMINATED</td><td>172.17.0.2:46027</td><td style=\"text-align: right;\">    0.000872243</td><td style=\"text-align: right;\">      124</td><td style=\"text-align: right;\">      112</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         192.704</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00006</td><td>TERMINATED</td><td>172.17.0.2:46028</td><td style=\"text-align: right;\">    0.000463264</td><td style=\"text-align: right;\">       77</td><td style=\"text-align: right;\">      125</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         172.471</td><td style=\"text-align: right;\">0.0741847  </td></tr>\n",
       "<tr><td>train_model_247ab_00007</td><td>TERMINATED</td><td>172.17.0.2:46029</td><td style=\"text-align: right;\">    0.000111618</td><td style=\"text-align: right;\">       17</td><td style=\"text-align: right;\">       76</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         147.666</td><td style=\"text-align: right;\">0.000969932</td></tr>\n",
       "<tr><td>train_model_247ab_00008</td><td>TERMINATED</td><td>172.17.0.2:46933</td><td style=\"text-align: right;\">    0.00013264 </td><td style=\"text-align: right;\">      104</td><td style=\"text-align: right;\">       21</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         169.5  </td><td style=\"text-align: right;\">0.0741452  </td></tr>\n",
       "<tr><td>train_model_247ab_00009</td><td>TERMINATED</td><td>172.17.0.2:46988</td><td style=\"text-align: right;\">    0.00012451 </td><td style=\"text-align: right;\">       87</td><td style=\"text-align: right;\">      118</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         168.713</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00010</td><td>TERMINATED</td><td>172.17.0.2:47039</td><td style=\"text-align: right;\">    0.000666344</td><td style=\"text-align: right;\">       59</td><td style=\"text-align: right;\">       31</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         146.403</td><td style=\"text-align: right;\">0.074161   </td></tr>\n",
       "<tr><td>train_model_247ab_00011</td><td>TERMINATED</td><td>172.17.0.2:47113</td><td style=\"text-align: right;\">    0.000261892</td><td style=\"text-align: right;\">       93</td><td style=\"text-align: right;\">      104</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         172.504</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00012</td><td>TERMINATED</td><td>172.17.0.2:47217</td><td style=\"text-align: right;\">    0.00814992 </td><td style=\"text-align: right;\">       50</td><td style=\"text-align: right;\">      100</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         150.752</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00013</td><td>TERMINATED</td><td>172.17.0.2:47279</td><td style=\"text-align: right;\">    0.000156677</td><td style=\"text-align: right;\">       17</td><td style=\"text-align: right;\">      114</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         138.218</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00014</td><td>TERMINATED</td><td>172.17.0.2:47356</td><td style=\"text-align: right;\">    0.000673328</td><td style=\"text-align: right;\">       33</td><td style=\"text-align: right;\">       38</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         141.103</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00015</td><td>TERMINATED</td><td>172.17.0.2:47434</td><td style=\"text-align: right;\">    0.000437681</td><td style=\"text-align: right;\">       19</td><td style=\"text-align: right;\">       66</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         133.544</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00016</td><td>TERMINATED</td><td>172.17.0.2:47783</td><td style=\"text-align: right;\">    0.000187068</td><td style=\"text-align: right;\">      127</td><td style=\"text-align: right;\">      118</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         182.856</td><td style=\"text-align: right;\">0.0757842  </td></tr>\n",
       "<tr><td>train_model_247ab_00017</td><td>TERMINATED</td><td>172.17.0.2:47885</td><td style=\"text-align: right;\">    0.000341837</td><td style=\"text-align: right;\">      116</td><td style=\"text-align: right;\">       77</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         181.946</td><td style=\"text-align: right;\">0.0739278  </td></tr>\n",
       "<tr><td>train_model_247ab_00018</td><td>TERMINATED</td><td>172.17.0.2:47937</td><td style=\"text-align: right;\">    0.00117706 </td><td style=\"text-align: right;\">       60</td><td style=\"text-align: right;\">       29</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         157.502</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00019</td><td>TERMINATED</td><td>172.17.0.2:47993</td><td style=\"text-align: right;\">    0.00369335 </td><td style=\"text-align: right;\">      106</td><td style=\"text-align: right;\">      120</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         180.007</td><td style=\"text-align: right;\">0.0736194  </td></tr>\n",
       "<tr><td>train_model_247ab_00020</td><td>TERMINATED</td><td>172.17.0.2:48074</td><td style=\"text-align: right;\">    0.000148826</td><td style=\"text-align: right;\">      115</td><td style=\"text-align: right;\">       77</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         176.632</td><td style=\"text-align: right;\">0.0731164  </td></tr>\n",
       "<tr><td>train_model_247ab_00021</td><td>TERMINATED</td><td>172.17.0.2:48131</td><td style=\"text-align: right;\">    0.000130971</td><td style=\"text-align: right;\">       70</td><td style=\"text-align: right;\">       37</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         150.099</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00022</td><td>TERMINATED</td><td>172.17.0.2:48185</td><td style=\"text-align: right;\">    0.000140718</td><td style=\"text-align: right;\">       38</td><td style=\"text-align: right;\">       48</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         159.072</td><td style=\"text-align: right;\">0.000327279</td></tr>\n",
       "<tr><td>train_model_247ab_00023</td><td>TERMINATED</td><td>172.17.0.2:48186</td><td style=\"text-align: right;\">    0.00112259 </td><td style=\"text-align: right;\">       58</td><td style=\"text-align: right;\">      107</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         159.492</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00024</td><td>TERMINATED</td><td>172.17.0.2:48709</td><td style=\"text-align: right;\">    0.0039528  </td><td style=\"text-align: right;\">       19</td><td style=\"text-align: right;\">       39</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         132.298</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00025</td><td>TERMINATED</td><td>172.17.0.2:48760</td><td style=\"text-align: right;\">    0.000161413</td><td style=\"text-align: right;\">      101</td><td style=\"text-align: right;\">       76</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         177.112</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00026</td><td>TERMINATED</td><td>172.17.0.2:48833</td><td style=\"text-align: right;\">    0.00528633 </td><td style=\"text-align: right;\">       64</td><td style=\"text-align: right;\">      120</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         163.316</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00027</td><td>TERMINATED</td><td>172.17.0.2:48912</td><td style=\"text-align: right;\">    0.00364046 </td><td style=\"text-align: right;\">      124</td><td style=\"text-align: right;\">       61</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         187.652</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00028</td><td>TERMINATED</td><td>172.17.0.2:48913</td><td style=\"text-align: right;\">    0.00788787 </td><td style=\"text-align: right;\">       40</td><td style=\"text-align: right;\">       59</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         141.42 </td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00029</td><td>TERMINATED</td><td>172.17.0.2:49044</td><td style=\"text-align: right;\">    0.000367198</td><td style=\"text-align: right;\">      108</td><td style=\"text-align: right;\">       38</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         177.288</td><td style=\"text-align: right;\">0.0716416  </td></tr>\n",
       "<tr><td>train_model_247ab_00030</td><td>TERMINATED</td><td>172.17.0.2:49095</td><td style=\"text-align: right;\">    0.00542368 </td><td style=\"text-align: right;\">       20</td><td style=\"text-align: right;\">       69</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         141.415</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00031</td><td>TERMINATED</td><td>172.17.0.2:49153</td><td style=\"text-align: right;\">    0.00138173 </td><td style=\"text-align: right;\">       32</td><td style=\"text-align: right;\">       77</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         140.699</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00032</td><td>TERMINATED</td><td>172.17.0.2:49510</td><td style=\"text-align: right;\">    0.00378118 </td><td style=\"text-align: right;\">      122</td><td style=\"text-align: right;\">       46</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         181.836</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00033</td><td>TERMINATED</td><td>172.17.0.2:49623</td><td style=\"text-align: right;\">    0.00199671 </td><td style=\"text-align: right;\">       90</td><td style=\"text-align: right;\">       60</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         165.95 </td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00034</td><td>TERMINATED</td><td>172.17.0.2:49713</td><td style=\"text-align: right;\">    0.00633969 </td><td style=\"text-align: right;\">      105</td><td style=\"text-align: right;\">       75</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         180.407</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00035</td><td>TERMINATED</td><td>172.17.0.2:49761</td><td style=\"text-align: right;\">    0.0003528  </td><td style=\"text-align: right;\">       98</td><td style=\"text-align: right;\">      108</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         164.661</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00036</td><td>TERMINATED</td><td>172.17.0.2:49825</td><td style=\"text-align: right;\">    0.000766412</td><td style=\"text-align: right;\">      112</td><td style=\"text-align: right;\">       86</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         179.757</td><td style=\"text-align: right;\">0.0731955  </td></tr>\n",
       "<tr><td>train_model_247ab_00037</td><td>TERMINATED</td><td>172.17.0.2:49909</td><td style=\"text-align: right;\">    0.00661205 </td><td style=\"text-align: right;\">       49</td><td style=\"text-align: right;\">      120</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         156.668</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00038</td><td>TERMINATED</td><td>172.17.0.2:50022</td><td style=\"text-align: right;\">    0.000403141</td><td style=\"text-align: right;\">       88</td><td style=\"text-align: right;\">       90</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         166.63 </td><td style=\"text-align: right;\">0.0719322  </td></tr>\n",
       "<tr><td>train_model_247ab_00039</td><td>TERMINATED</td><td>172.17.0.2:50073</td><td style=\"text-align: right;\">    0.000499123</td><td style=\"text-align: right;\">       76</td><td style=\"text-align: right;\">      119</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         170.496</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00040</td><td>TERMINATED</td><td>172.17.0.2:50447</td><td style=\"text-align: right;\">    0.00128677 </td><td style=\"text-align: right;\">      108</td><td style=\"text-align: right;\">      117</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         177.669</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00041</td><td>TERMINATED</td><td>172.17.0.2:50515</td><td style=\"text-align: right;\">    0.00032354 </td><td style=\"text-align: right;\">       30</td><td style=\"text-align: right;\">       30</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         139.663</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00042</td><td>TERMINATED</td><td>172.17.0.2:50604</td><td style=\"text-align: right;\">    0.000332941</td><td style=\"text-align: right;\">       44</td><td style=\"text-align: right;\">       39</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         147.443</td><td style=\"text-align: right;\">0.0716942  </td></tr>\n",
       "<tr><td>train_model_247ab_00043</td><td>TERMINATED</td><td>172.17.0.2:50660</td><td style=\"text-align: right;\">    0.001721   </td><td style=\"text-align: right;\">       29</td><td style=\"text-align: right;\">       23</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         140.285</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00044</td><td>TERMINATED</td><td>172.17.0.2:50749</td><td style=\"text-align: right;\">    0.00334767 </td><td style=\"text-align: right;\">       92</td><td style=\"text-align: right;\">       75</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         160.944</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00045</td><td>TERMINATED</td><td>172.17.0.2:50809</td><td style=\"text-align: right;\">    0.000532343</td><td style=\"text-align: right;\">       49</td><td style=\"text-align: right;\">       90</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         143.156</td><td style=\"text-align: right;\">0.0718646  </td></tr>\n",
       "<tr><td>train_model_247ab_00046</td><td>TERMINATED</td><td>172.17.0.2:50913</td><td style=\"text-align: right;\">    0.00160765 </td><td style=\"text-align: right;\">       81</td><td style=\"text-align: right;\">       68</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         158.817</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00047</td><td>TERMINATED</td><td>172.17.0.2:50988</td><td style=\"text-align: right;\">    0.000109009</td><td style=\"text-align: right;\">       43</td><td style=\"text-align: right;\">      114</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         136.272</td><td style=\"text-align: right;\">0.000318674</td></tr>\n",
       "<tr><td>train_model_247ab_00048</td><td>TERMINATED</td><td>172.17.0.2:51282</td><td style=\"text-align: right;\">    0.000166253</td><td style=\"text-align: right;\">       48</td><td style=\"text-align: right;\">      114</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         112.366</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00049</td><td>TERMINATED</td><td>172.17.0.2:51378</td><td style=\"text-align: right;\">    0.000765451</td><td style=\"text-align: right;\">      117</td><td style=\"text-align: right;\">       35</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         126.711</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_model pid=46029)\u001b[0m \n",
      "\u001b[36m(train_model pid=46023)\u001b[0m \n",
      "\u001b[36m(train_model pid=46028)\u001b[0m \n",
      "\u001b[36m(train_model pid=46024)\u001b[0m \n",
      "\u001b[36m(train_model pid=46022)\u001b[0m \n",
      "\u001b[36m(train_model pid=46026)\u001b[0m \n",
      "\u001b[36m(train_model pid=46027)\u001b[0m \n",
      "\u001b[36m(train_model pid=46025)\u001b[0m \n",
      "\u001b[36m(train_model pid=46029)\u001b[0m Loss: 15266.570238834234\n",
      "\u001b[36m(train_model pid=46029)\u001b[0m Loss: 1160.1594111709855\u001b[32m [repeated 16x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(train_model pid=46023)\u001b[0m Loss: 19834.02746124824\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46029)\u001b[0m Loss: 1098.2790231795516\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46023)\u001b[0m Loss: 776.2787184864283\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46026)\u001b[0m Loss: 28884.76565052433\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46023)\u001b[0m Loss: 795.2306010648608\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46029)\u001b[0m Loss: 1081.4055783916265\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46029)\u001b[0m Loss: 1084.6113083439413\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46028)\u001b[0m Loss: 25753.623072835388\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46029)\u001b[0m \n",
      "\u001b[36m(train_model pid=46024)\u001b[0m \n",
      "\u001b[36m(train_model pid=46026)\u001b[0m \n",
      "\u001b[36m(train_model pid=46022)\u001b[0m Loss: 25489.44246892417\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46022)\u001b[0m \n",
      "\u001b[36m(train_model pid=46022)\u001b[0m Loss: 25264.673917057095\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46025)\u001b[0m \n",
      "\u001b[36m(train_model pid=46028)\u001b[0m \n",
      "\u001b[36m(train_model pid=46029)\u001b[0m Loss: 1141.012488890672\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46027)\u001b[0m \n",
      "\u001b[36m(train_model pid=46023)\u001b[0m \n",
      "\u001b[36m(train_model pid=46022)\u001b[0m Loss: 25343.482799390404\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46024)\u001b[0m Loss: 26564.374554906964\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46027)\u001b[0m Loss: 32896.64620357514\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46026)\u001b[0m Loss: 75085.0750954215\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46026)\u001b[0m Loss: 174425.9187184048\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46023)\u001b[0m Loss: 25743.75\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46029)\u001b[0m \n",
      "\u001b[36m(train_model pid=46024)\u001b[0m \n",
      "\u001b[36m(train_model pid=46026)\u001b[0m Loss: 52392.98933739608\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46026)\u001b[0m \n",
      "\u001b[36m(train_model pid=46022)\u001b[0m \n",
      "\u001b[36m(train_model pid=46023)\u001b[0m Loss: 25757.5\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46024)\u001b[0m Loss: 25180.728289823797\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46028)\u001b[0m \n",
      "\u001b[36m(train_model pid=46027)\u001b[0m Loss: 5672.443571231475\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46025)\u001b[0m \n",
      "\u001b[36m(train_model pid=46024)\u001b[0m Loss: 774.3788915574551\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46024)\u001b[0m Loss: 771.6618947982788\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46023)\u001b[0m \n",
      "\u001b[36m(train_model pid=46027)\u001b[0m \n",
      "\u001b[36m(train_model pid=46025)\u001b[0m Loss: 25882.519009162053\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46022)\u001b[0m Loss: 784.0521525219083\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46025)\u001b[0m Loss: 2703.6949338167906\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46029)\u001b[0m ROC AUC scores for each fold: [0.49845468557114986, 0.5041181230415557, 0.4957975402114874]\n",
      "\u001b[36m(train_model pid=46029)\u001b[0m Average ROC AUC: 0.4994567829413976\n",
      "\u001b[36m(train_model pid=46029)\u001b[0m PR AUC scores for each fold: [0.12256635688526027, 0.1263973493314449, 0.11918255388488005]\n",
      "\u001b[36m(train_model pid=46029)\u001b[0m Average PR AUC: 0.12271542003386175\n",
      "\u001b[36m(train_model pid=46029)\u001b[0m F1 scores for each fold: [0.002909796314258002, 0.0, 0.0]\n",
      "\u001b[36m(train_model pid=46029)\u001b[0m Average F1 score: 0.0009699321047526673\n",
      "\u001b[36m(train_model pid=46025)\u001b[0m Loss: 784.2274559438229\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46933)\u001b[0m \n",
      "\u001b[36m(train_model pid=46024)\u001b[0m ROC AUC scores for each fold: [0.4994402053958243, 0.5000340715502556, 0.5002059449440517]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46024)\u001b[0m Average ROC AUC: 0.4998934072967105\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46024)\u001b[0m PR AUC scores for each fold: [0.12402114595896786, 0.11952478099123964, 0.12599039615846339]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46024)\u001b[0m Average PR AUC: 0.12317877436955697\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46024)\u001b[0m F1 scores for each fold: [0.0, 0.0, 0.0]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46024)\u001b[0m Average F1 score: 0.0\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46988)\u001b[0m \n",
      "\u001b[36m(train_model pid=47039)\u001b[0m \n",
      "\u001b[36m(train_model pid=46933)\u001b[0m Loss: 26667.328100518123\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46022)\u001b[0m ROC AUC scores for each fold: [0.49995445152777335, 0.5012274530926841, 0.5001926162814335]\n",
      "\u001b[36m(train_model pid=46022)\u001b[0m Average ROC AUC: 0.5004581736339637\n",
      "\u001b[36m(train_model pid=46022)\u001b[0m PR AUC scores for each fold: [0.12406057578455013, 0.1256817186350295, 0.11986547205175924]\n",
      "\u001b[36m(train_model pid=46022)\u001b[0m Average PR AUC: 0.12320258882377962\n",
      "\u001b[36m(train_model pid=46022)\u001b[0m F1 scores for each fold: [0.0, 0.0, 0.0]\n",
      "\u001b[36m(train_model pid=46022)\u001b[0m Average F1 score: 0.0\n",
      "\u001b[36m(train_model pid=47113)\u001b[0m \n",
      "\u001b[36m(train_model pid=46988)\u001b[0m Loss: 28474.07671776163\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46025)\u001b[0m Loss: 784.5518295094371\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46028)\u001b[0m ROC AUC scores for each fold: [0.5010879623008927, 0.4995879998315264, 0.5004115226337449]\n",
      "\u001b[36m(train_model pid=46028)\u001b[0m Average ROC AUC: 0.5003624949220546\n",
      "\u001b[36m(train_model pid=46028)\u001b[0m PR AUC scores for each fold: [0.12246168209080151, 0.12252997831237618, 0.12525519394740003]\n",
      "\u001b[36m(train_model pid=46028)\u001b[0m Average PR AUC: 0.12341561811685924\n",
      "\u001b[36m(train_model pid=46028)\u001b[0m F1 scores for each fold: [0.0, 0.0, 0.22255414488424197]\n",
      "\u001b[36m(train_model pid=46028)\u001b[0m Average F1 score: 0.07418471496141399\n",
      "\u001b[36m(train_model pid=46028)\u001b[0m Loss: 166459.11532508524\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46025)\u001b[0m ROC AUC scores for each fold: [0.5000683386865304, 0.5000051170920201, 0.5000681663258351]\n",
      "\u001b[36m(train_model pid=46025)\u001b[0m Average ROC AUC: 0.5000472073681285\n",
      "\u001b[36m(train_model pid=46025)\u001b[0m PR AUC scores for each fold: [0.12205220522052206, 0.1273786044170449, 0.11977916466634661]\n",
      "\u001b[36m(train_model pid=46025)\u001b[0m Average PR AUC: 0.12306999143463786\n",
      "\u001b[36m(train_model pid=46025)\u001b[0m F1 scores for each fold: [0.0, 0.0, 0.0]\n",
      "\u001b[36m(train_model pid=46025)\u001b[0m Average F1 score: 0.0\n",
      "\u001b[36m(train_model pid=46023)\u001b[0m Loss: 25658.333332061768\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47217)\u001b[0m \n",
      "\u001b[36m(train_model pid=47279)\u001b[0m \n",
      "\u001b[36m(train_model pid=46023)\u001b[0m Loss: 25647.916666151672\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46023)\u001b[0m ROC AUC scores for each fold: [0.5000342512672968, 0.5001433298115727, 0.49976053639846746]\n",
      "\u001b[36m(train_model pid=46023)\u001b[0m Average ROC AUC: 0.4999793724924457\n",
      "\u001b[36m(train_model pid=46023)\u001b[0m PR AUC scores for each fold: [0.12414496579863195, 0.12222338149107224, 0.12300492019680788]\n",
      "\u001b[36m(train_model pid=46023)\u001b[0m Average PR AUC: 0.12312442249550402\n",
      "\u001b[36m(train_model pid=46023)\u001b[0m F1 scores for each fold: [0.0, 0.0, 0.0]\n",
      "\u001b[36m(train_model pid=46023)\u001b[0m Average F1 score: 0.0\n",
      "\u001b[36m(train_model pid=47113)\u001b[0m Loss: 26298.666714757885\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47356)\u001b[0m \n",
      "\u001b[36m(train_model pid=46027)\u001b[0m ROC AUC scores for each fold: [0.5007071239370507, 0.5001715383559764, 0.4982382341239235]\n",
      "\u001b[36m(train_model pid=46027)\u001b[0m Average ROC AUC: 0.4997056321389836\n",
      "\u001b[36m(train_model pid=46027)\u001b[0m PR AUC scores for each fold: [0.12418113264602358, 0.12561517224822952, 0.12007267119682997]\n",
      "\u001b[36m(train_model pid=46027)\u001b[0m Average PR AUC: 0.12328965869702768\n",
      "\u001b[36m(train_model pid=46027)\u001b[0m F1 scores for each fold: [0.0, 0.0, 0.0]\n",
      "\u001b[36m(train_model pid=46027)\u001b[0m Average F1 score: 0.0\n",
      "\u001b[36m(train_model pid=47039)\u001b[0m Loss: 54249.0882248465\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47434)\u001b[0m \n",
      "\u001b[36m(train_model pid=47356)\u001b[0m Loss: 25087.45637751115\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47217)\u001b[0m Loss: 25565.154153347015\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47039)\u001b[0m \n",
      "\u001b[36m(train_model pid=46988)\u001b[0m \n",
      "\u001b[36m(train_model pid=47279)\u001b[0m Loss: 1645.4559872788723\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46933)\u001b[0m \n",
      "\u001b[36m(train_model pid=47113)\u001b[0m Loss: 25485.03759590431\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47113)\u001b[0m \n",
      "\u001b[36m(train_model pid=47039)\u001b[0m Loss: 51323.62179682027\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47279)\u001b[0m \n",
      "\u001b[36m(train_model pid=47279)\u001b[0m Loss: 6591.65491534821\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47217)\u001b[0m Loss: 25537.500000949607\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47217)\u001b[0m \n",
      "\u001b[36m(train_model pid=47356)\u001b[0m Loss: 769.9270033761859\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47356)\u001b[0m \n",
      "\u001b[36m(train_model pid=47434)\u001b[0m \n",
      "\u001b[36m(train_model pid=46933)\u001b[0m Loss: 25317.08766502918\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46933)\u001b[0m Loss: 25353.98021426471\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47434)\u001b[0m Loss: 24955.760441191647\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47039)\u001b[0m \n",
      "\u001b[36m(train_model pid=47113)\u001b[0m Loss: 25157.637508428797\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47279)\u001b[0m Loss: 1769.16284133425\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46933)\u001b[0m \n",
      "\u001b[36m(train_model pid=46988)\u001b[0m \n",
      "\u001b[36m(train_model pid=47356)\u001b[0m Loss: 153652.88392154803\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47279)\u001b[0m \n",
      "\u001b[36m(train_model pid=46988)\u001b[0m Loss: 27317.778922775833\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47113)\u001b[0m Loss: 25153.984751464057\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47113)\u001b[0m \n",
      "\u001b[36m(train_model pid=47356)\u001b[0m \n",
      "\u001b[36m(train_model pid=47279)\u001b[0m Loss: 1275.3156577000354\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47434)\u001b[0m \n",
      "\u001b[36m(train_model pid=47217)\u001b[0m \n",
      "\u001b[36m(train_model pid=47039)\u001b[0m Loss: 25352.45822879936\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47434)\u001b[0m Loss: 25187.47618020182\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46988)\u001b[0m Loss: 156266.42700229108\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47039)\u001b[0m ROC AUC scores for each fold: [0.499876163724833, 0.5000341973873197, 0.500103275215132]\n",
      "\u001b[36m(train_model pid=47039)\u001b[0m Average ROC AUC: 0.5000045454424282\n",
      "\u001b[36m(train_model pid=47039)\u001b[0m PR AUC scores for each fold: [0.1219629594009521, 0.1227796447431589, 0.12518764210545405]\n",
      "\u001b[36m(train_model pid=47039)\u001b[0m Average PR AUC: 0.12331008208318835\n",
      "\u001b[36m(train_model pid=47039)\u001b[0m F1 scores for each fold: [0.0, 0.0, 0.2224829351535836]\n",
      "\u001b[36m(train_model pid=47039)\u001b[0m Average F1 score: 0.07416097838452787\n",
      "\u001b[36m(train_model pid=46988)\u001b[0m Loss: 25521.489995280597\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47783)\u001b[0m \n",
      "\u001b[36m(train_model pid=47217)\u001b[0m Loss: 25597.916666030884\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47279)\u001b[0m Loss: 1051.0538626662455\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47279)\u001b[0m ROC AUC scores for each fold: [0.49552515347052345, 0.4987967551215853, 0.4972048296103385]\n",
      "\u001b[36m(train_model pid=47279)\u001b[0m Average ROC AUC: 0.4971755794008157\n",
      "\u001b[36m(train_model pid=47279)\u001b[0m PR AUC scores for each fold: [0.12502822522431378, 0.1184171181239835, 0.12269882215131443]\n",
      "\u001b[36m(train_model pid=47279)\u001b[0m Average PR AUC: 0.12204805516653723\n",
      "\u001b[36m(train_model pid=47279)\u001b[0m F1 scores for each fold: [0.0, 0.0, 0.0]\n",
      "\u001b[36m(train_model pid=47279)\u001b[0m Average F1 score: 0.0\n",
      "\u001b[36m(train_model pid=46988)\u001b[0m Loss: 25495.915275890522\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47885)\u001b[0m \n",
      "\u001b[36m(train_model pid=46988)\u001b[0m ROC AUC scores for each fold: [0.5000569963105282, 0.4980874229914537, 0.49810578561860086]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46988)\u001b[0m Average ROC AUC: 0.4987500683068609\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46988)\u001b[0m PR AUC scores for each fold: [0.12246848925319491, 0.12482364601216508, 0.12179494366654083]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46988)\u001b[0m Average PR AUC: 0.1230290263106336\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46988)\u001b[0m F1 scores for each fold: [0.0, 0.0, 0.0]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=46988)\u001b[0m Average F1 score: 0.0\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47356)\u001b[0m Loss: 779.7364345863461\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47937)\u001b[0m \n",
      "\u001b[36m(train_model pid=47993)\u001b[0m \n",
      "\u001b[36m(train_model pid=47217)\u001b[0m ROC AUC scores for each fold: [0.49982877885076366, 0.5, 0.5000032750569369]\n",
      "\u001b[36m(train_model pid=47217)\u001b[0m Average ROC AUC: 0.49994401796923355\n",
      "\u001b[36m(train_model pid=47217)\u001b[0m PR AUC scores for each fold: [0.123957520849583, 0.12167756644867103, 0.12364683028311906]\n",
      "\u001b[36m(train_model pid=47217)\u001b[0m Average PR AUC: 0.12309397252712435\n",
      "\u001b[36m(train_model pid=47217)\u001b[0m F1 scores for each fold: [0.0, 0.0, 0.0]\n",
      "\u001b[36m(train_model pid=47217)\u001b[0m Average F1 score: 0.0\n",
      "\u001b[36m(train_model pid=47356)\u001b[0m ROC AUC scores for each fold: [0.5001374098248025, 0.4996295494126886, 0.5000955398333511]\n",
      "\u001b[36m(train_model pid=47356)\u001b[0m Average ROC AUC: 0.4999541663569474\n",
      "\u001b[36m(train_model pid=47356)\u001b[0m PR AUC scores for each fold: [0.12674788453459762, 0.12082608398160603, 0.12194536247495413]\n",
      "\u001b[36m(train_model pid=47356)\u001b[0m Average PR AUC: 0.12317311033038593\n",
      "\u001b[36m(train_model pid=47356)\u001b[0m F1 scores for each fold: [0.0, 0.0, 0.0]\n",
      "\u001b[36m(train_model pid=47356)\u001b[0m Average F1 score: 0.0\n",
      "\u001b[36m(train_model pid=47356)\u001b[0m Loss: 779.9284497201443\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48074)\u001b[0m \n",
      "\u001b[36m(train_model pid=48131)\u001b[0m \n",
      "\u001b[36m(train_model pid=47113)\u001b[0m ROC AUC scores for each fold: [0.49695767845626343, 0.5006767516129852, 0.5016810160781242]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47113)\u001b[0m Average ROC AUC: 0.4997718153824576\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47113)\u001b[0m PR AUC scores for each fold: [0.11980923973212085, 0.1281622635885968, 0.12172189661702963]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47113)\u001b[0m Average PR AUC: 0.12323113331258244\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47113)\u001b[0m F1 scores for each fold: [0.0, 0.0, 0.0]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47113)\u001b[0m Average F1 score: 0.0\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48074)\u001b[0m Loss: 27779.261468463596\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48186)\u001b[0m \n",
      "\u001b[36m(train_model pid=48185)\u001b[0m \n",
      "\u001b[36m(train_model pid=48074)\u001b[0m Loss: 131562.66483675488\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48074)\u001b[0m Loss: 25331.184695826752\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47937)\u001b[0m Loss: 776.650341026485\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47937)\u001b[0m Loss: 776.2871277183294\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47885)\u001b[0m Loss: 25334.484528070327\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47783)\u001b[0m \n",
      "\u001b[36m(train_model pid=47993)\u001b[0m Loss: 25720.0\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48074)\u001b[0m Loss: 25506.232324192788\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47937)\u001b[0m \n",
      "\u001b[36m(train_model pid=48131)\u001b[0m Loss: 25307.458696939753\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47885)\u001b[0m \n",
      "\u001b[36m(train_model pid=48186)\u001b[0m Loss: 81912.68575750235\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48131)\u001b[0m \n",
      "\u001b[36m(train_model pid=47783)\u001b[0m \n",
      "\u001b[36m(train_model pid=47993)\u001b[0m Loss: 25706.250000000153\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47993)\u001b[0m \n",
      "\u001b[36m(train_model pid=48186)\u001b[0m \n",
      "\u001b[36m(train_model pid=48074)\u001b[0m \n",
      "\u001b[36m(train_model pid=48185)\u001b[0m \n",
      "\u001b[36m(train_model pid=47993)\u001b[0m Loss: 25533.30002975464\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48186)\u001b[0m Loss: 25589.732338063855\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47993)\u001b[0m Loss: 25532.54298457876\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48186)\u001b[0m Loss: 25622.59238052368\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47937)\u001b[0m Loss: 782.9105553925037\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47937)\u001b[0m Loss: 783.3312282934785\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47783)\u001b[0m \n",
      "\u001b[36m(train_model pid=48074)\u001b[0m Loss: 35751.53603788809\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47937)\u001b[0m \n",
      "\u001b[36m(train_model pid=47993)\u001b[0m Loss: 48788.145855903625\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48131)\u001b[0m \n",
      "\u001b[36m(train_model pid=48185)\u001b[0m Loss: 1316.4490763982758\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48185)\u001b[0m Loss: 1181.1189428127836\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48185)\u001b[0m \n",
      "\u001b[36m(train_model pid=48186)\u001b[0m \n",
      "\u001b[36m(train_model pid=47885)\u001b[0m \n",
      "\u001b[36m(train_model pid=47993)\u001b[0m \n",
      "\u001b[36m(train_model pid=47885)\u001b[0m Loss: 41056.12933831709\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47885)\u001b[0m Loss: 25182.826680785736\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48074)\u001b[0m \n",
      "\u001b[36m(train_model pid=47783)\u001b[0m Loss: 25629.751573733498\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47885)\u001b[0m Loss: 25251.70129660632\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47993)\u001b[0m Loss: 7698.66153586768\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47937)\u001b[0m Loss: 25430.31321778624\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47937)\u001b[0m Loss: 1359.1178030222654\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=47937)\u001b[0m ROC AUC scores for each fold: [0.49857835713225507, 0.5001364163426778, 0.49982874135504024]\n",
      "\u001b[36m(train_model pid=47937)\u001b[0m Average ROC AUC: 0.49951450494332433\n",
      "\u001b[36m(train_model pid=47937)\u001b[0m PR AUC scores for each fold: [0.12348919625068591, 0.12038648502670588, 0.12506753283376984]\n",
      "\u001b[36m(train_model pid=47937)\u001b[0m Average PR AUC: 0.1229810713703872\n",
      "\u001b[36m(train_model pid=47937)\u001b[0m F1 scores for each fold: [0.0, 0.0, 0.0]\n",
      "\u001b[36m(train_model pid=47937)\u001b[0m Average F1 score: 0.0\n",
      "\u001b[36m(train_model pid=48074)\u001b[0m Loss: 108802.63636387303\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48709)\u001b[0m \n",
      "\u001b[36m(train_model pid=48131)\u001b[0m ROC AUC scores for each fold: [0.49776496806013165, 0.5022221552983062, 0.5000959898502603]\n",
      "\u001b[36m(train_model pid=48131)\u001b[0m Average ROC AUC: 0.5000277044028993\n",
      "\u001b[36m(train_model pid=48131)\u001b[0m PR AUC scores for each fold: [0.12525040342684096, 0.12547370636901797, 0.11980783809995675]\n",
      "\u001b[36m(train_model pid=48131)\u001b[0m Average PR AUC: 0.12351064929860522\n",
      "\u001b[36m(train_model pid=48131)\u001b[0m F1 scores for each fold: [0.0, 0.0, 0.0]\n",
      "\u001b[36m(train_model pid=48131)\u001b[0m Average F1 score: 0.0\n",
      "\u001b[36m(train_model pid=48760)\u001b[0m \n",
      "\u001b[36m(train_model pid=47783)\u001b[0m ROC AUC scores for each fold: [0.49952417475841887, 0.5000209979771735, 0.49929401067014795]\n",
      "\u001b[36m(train_model pid=47783)\u001b[0m Average ROC AUC: 0.4996130611352468\n",
      "\u001b[36m(train_model pid=47783)\u001b[0m PR AUC scores for each fold: [0.11973373551199527, 0.12822213945392047, 0.12203186853904346]\n",
      "\u001b[36m(train_model pid=47783)\u001b[0m Average PR AUC: 0.1233292478349864\n",
      "\u001b[36m(train_model pid=47783)\u001b[0m F1 scores for each fold: [0.0, 0.2273525187509974, 0.0]\n",
      "\u001b[36m(train_model pid=47783)\u001b[0m Average F1 score: 0.07578417291699914\n",
      "\u001b[36m(train_model pid=47885)\u001b[0m Loss: 37000.99227294332\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48833)\u001b[0m \n",
      "\u001b[36m(train_model pid=48185)\u001b[0m ROC AUC scores for each fold: [0.4890918383598064, 0.5056390220731993, 0.49885545566413664]\n",
      "\u001b[36m(train_model pid=48185)\u001b[0m Average ROC AUC: 0.4978621053657141\n",
      "\u001b[36m(train_model pid=48185)\u001b[0m PR AUC scores for each fold: [0.11930410013736399, 0.1277913679981896, 0.1208664171159259]\n",
      "\u001b[36m(train_model pid=48185)\u001b[0m Average PR AUC: 0.12265396175049316\n",
      "\u001b[36m(train_model pid=48185)\u001b[0m F1 scores for each fold: [0.0, 0.0, 0.0009818360333824251]\n",
      "\u001b[36m(train_model pid=48185)\u001b[0m Average F1 score: 0.0003272786777941417\n",
      "\u001b[36m(train_model pid=48185)\u001b[0m Loss: 37996.9108809181\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48912)\u001b[0m \n",
      "\u001b[36m(train_model pid=48186)\u001b[0m ROC AUC scores for each fold: [0.4999288038934612, 0.5001026132165822, 0.5001709401709402]\n",
      "\u001b[36m(train_model pid=48186)\u001b[0m Average ROC AUC: 0.5000674524269946\n",
      "\u001b[36m(train_model pid=48186)\u001b[0m PR AUC scores for each fold: [0.12376209379430839, 0.12295967354776764, 0.1225016505611908]\n",
      "\u001b[36m(train_model pid=48186)\u001b[0m Average PR AUC: 0.12307447263442228\n",
      "\u001b[36m(train_model pid=48186)\u001b[0m F1 scores for each fold: [0.0, 0.0, 0.0]\n",
      "\u001b[36m(train_model pid=48186)\u001b[0m Average F1 score: 0.0\n",
      "\u001b[36m(train_model pid=48760)\u001b[0m Loss: 130476.83655979685\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48913)\u001b[0m \n",
      "\u001b[36m(train_model pid=47885)\u001b[0m ROC AUC scores for each fold: [0.49759765428446223, 0.5001202441045731, 0.4989971585278605]\n",
      "\u001b[36m(train_model pid=47885)\u001b[0m Average ROC AUC: 0.4989050189722986\n",
      "\u001b[36m(train_model pid=47885)\u001b[0m PR AUC scores for each fold: [0.12183141908166206, 0.12323423796942184, 0.12446605500019356]\n",
      "\u001b[36m(train_model pid=47885)\u001b[0m Average PR AUC: 0.12317723735042581\n",
      "\u001b[36m(train_model pid=47885)\u001b[0m F1 scores for each fold: [0.0, 0.0, 0.22178344628848926]\n",
      "\u001b[36m(train_model pid=47885)\u001b[0m Average F1 score: 0.07392781542949642\n",
      "\u001b[36m(train_model pid=47885)\u001b[0m Loss: 25816.20534093877\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=49044)\u001b[0m \n",
      "\u001b[36m(train_model pid=48074)\u001b[0m ROC AUC scores for each fold: [0.5014430777232143, 0.4995161694756437, 0.5011131068103656]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48074)\u001b[0m Average ROC AUC: 0.5006907846697412\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48074)\u001b[0m PR AUC scores for each fold: [0.12349030832348419, 0.12447181812220175, 0.12272203867830062]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48074)\u001b[0m Average PR AUC: 0.12356138837466218\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48074)\u001b[0m F1 scores for each fold: [0.21934932421603717, 0.0, 0.0]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48074)\u001b[0m Average F1 score: 0.07311644140534572\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48833)\u001b[0m Loss: 25375.19327545166\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=49095)\u001b[0m \n",
      "\u001b[36m(train_model pid=49153)\u001b[0m \n",
      "\u001b[36m(train_model pid=48912)\u001b[0m Loss: 16357.148862078786\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48913)\u001b[0m Loss: 25895.0\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=49153)\u001b[0m Loss: 779.0714064538479\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48709)\u001b[0m \n",
      "\u001b[36m(train_model pid=49044)\u001b[0m Loss: 25496.1875496789\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=49095)\u001b[0m Loss: 779.1089254841208\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48709)\u001b[0m Loss: 772.9241608828306\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48760)\u001b[0m \n",
      "\u001b[36m(train_model pid=49153)\u001b[0m Loss: 777.7039878964424\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48913)\u001b[0m \n",
      "\u001b[36m(train_model pid=48833)\u001b[0m \n",
      "\u001b[36m(train_model pid=48709)\u001b[0m Loss: 773.1860005781054\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=49095)\u001b[0m Loss: 779.1941049322486\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=49095)\u001b[0m \n",
      "\u001b[36m(train_model pid=49153)\u001b[0m \n",
      "\u001b[36m(train_model pid=48912)\u001b[0m \n",
      "\u001b[36m(train_model pid=49044)\u001b[0m Loss: 25499.78337054275\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=49044)\u001b[0m \n",
      "\u001b[36m(train_model pid=48709)\u001b[0m Loss: 772.7572043165565\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48709)\u001b[0m \n",
      "\u001b[36m(train_model pid=49153)\u001b[0m Loss: 782.5689544826746\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48913)\u001b[0m Loss: 773.0647292360663\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48709)\u001b[0m Loss: 779.8487471714616\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=49153)\u001b[0m Loss: 783.0135307982564\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48913)\u001b[0m \n",
      "\u001b[36m(train_model pid=49095)\u001b[0m Loss: 25670.0\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48760)\u001b[0m Loss: 25235.49630273842\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48760)\u001b[0m \n",
      "\u001b[36m(train_model pid=48833)\u001b[0m \n",
      "\u001b[36m(train_model pid=49153)\u001b[0m \n",
      "\u001b[36m(train_model pid=48912)\u001b[0m Loss: 25937.5\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=49095)\u001b[0m \n",
      "\u001b[36m(train_model pid=49153)\u001b[0m Loss: 1730.646887643878\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48913)\u001b[0m Loss: 778.7785774022341\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48709)\u001b[0m ROC AUC scores for each fold: [0.500110451539796, 0.5001039424096055, 0.5]\n",
      "\u001b[36m(train_model pid=48709)\u001b[0m Average ROC AUC: 0.5000714646498006\n",
      "\u001b[36m(train_model pid=48709)\u001b[0m PR AUC scores for each fold: [0.1215422628306327, 0.1254878305742225, 0.12228489139565582]\n",
      "\u001b[36m(train_model pid=48709)\u001b[0m Average PR AUC: 0.12310499493350369\n",
      "\u001b[36m(train_model pid=48709)\u001b[0m F1 scores for each fold: [0.0, 0.0, 0.0]\n",
      "\u001b[36m(train_model pid=48709)\u001b[0m Average F1 score: 0.0\n",
      "\u001b[36m(train_model pid=49153)\u001b[0m Loss: 773.9956257119775\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48912)\u001b[0m \n",
      "\u001b[36m(train_model pid=49510)\u001b[0m \n",
      "\u001b[36m(train_model pid=49044)\u001b[0m Loss: 25290.55650643049\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=49044)\u001b[0m \n",
      "\u001b[36m(train_model pid=49044)\u001b[0m Loss: 25829.49921211623\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48833)\u001b[0m Loss: 25870.833332061768\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48913)\u001b[0m ROC AUC scores for each fold: [0.500214373940594, 0.5000686106346484, 0.5001710337278511]\n",
      "\u001b[36m(train_model pid=48913)\u001b[0m Average ROC AUC: 0.5001513394343645\n",
      "\u001b[36m(train_model pid=48913)\u001b[0m PR AUC scores for each fold: [0.12090609579458511, 0.12553255325532553, 0.12298181381669768]\n",
      "\u001b[36m(train_model pid=48913)\u001b[0m Average PR AUC: 0.12314015428886944\n",
      "\u001b[36m(train_model pid=48913)\u001b[0m F1 scores for each fold: [0.0, 0.0, 0.0]\n",
      "\u001b[36m(train_model pid=48913)\u001b[0m Average F1 score: 0.0\n",
      "\u001b[36m(train_model pid=49510)\u001b[0m Loss: 25706.250000010754\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=49623)\u001b[0m \n",
      "\u001b[36m(train_model pid=49153)\u001b[0m Loss: 772.6958546340466\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=49095)\u001b[0m ROC AUC scores for each fold: [0.5, 0.500141584528268, 0.5000684837693467]\n",
      "\u001b[36m(train_model pid=49095)\u001b[0m Average ROC AUC: 0.5000700227658715\n",
      "\u001b[36m(train_model pid=49095)\u001b[0m PR AUC scores for each fold: [0.12245755084898302, 0.12330582489912702, 0.12386725079517494]\n",
      "\u001b[36m(train_model pid=49095)\u001b[0m Average PR AUC: 0.12321020884776164\n",
      "\u001b[36m(train_model pid=49095)\u001b[0m F1 scores for each fold: [0.0, 0.0, 0.0]\n",
      "\u001b[36m(train_model pid=49095)\u001b[0m Average F1 score: 0.0\n",
      "\u001b[36m(train_model pid=49153)\u001b[0m Loss: 772.5270410999656\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=49713)\u001b[0m \n",
      "\u001b[36m(train_model pid=48833)\u001b[0m ROC AUC scores for each fold: [0.49989706992383176, 0.49996581196581197, 0.5001796288649354]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48833)\u001b[0m Average ROC AUC: 0.5000141702515264\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48833)\u001b[0m PR AUC scores for each fold: [0.125637487250255, 0.12251754964900702, 0.12121273150380651]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48833)\u001b[0m Average PR AUC: 0.1231225894676895\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48833)\u001b[0m F1 scores for each fold: [0.0, 0.0, 0.0]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48833)\u001b[0m Average F1 score: 0.0\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=49761)\u001b[0m \n",
      "\u001b[36m(train_model pid=49044)\u001b[0m Loss: 72548.98273919667\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=49825)\u001b[0m \n",
      "\u001b[36m(train_model pid=48760)\u001b[0m Loss: 108880.25391082288\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48760)\u001b[0m ROC AUC scores for each fold: [0.4994663177917462, 0.49938307036598767, 0.5000813585595827]\n",
      "\u001b[36m(train_model pid=48760)\u001b[0m Average ROC AUC: 0.4996435822391055\n",
      "\u001b[36m(train_model pid=48760)\u001b[0m PR AUC scores for each fold: [0.12368455577302882, 0.12588650200105692, 0.12050471012019497]\n",
      "\u001b[36m(train_model pid=48760)\u001b[0m Average PR AUC: 0.12335858929809357\n",
      "\u001b[36m(train_model pid=48760)\u001b[0m F1 scores for each fold: [0.0, 0.0, 0.0]\n",
      "\u001b[36m(train_model pid=48760)\u001b[0m Average F1 score: 0.0\n",
      "\u001b[36m(train_model pid=49909)\u001b[0m \n",
      "\u001b[36m(train_model pid=49044)\u001b[0m Loss: 59297.87129148963\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=49623)\u001b[0m Loss: 5033.136345498308\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=48912)\u001b[0m Loss: 25360.416671283536\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=49510)\u001b[0m \n",
      "\u001b[36m(train_model pid=49044)\u001b[0m ROC AUC scores for each fold: [0.49959481197759364, 0.4985882951203874, 0.5001259830989926]\n",
      "\u001b[36m(train_model pid=49044)\u001b[0m Average ROC AUC: 0.49943636339899117\n",
      "\u001b[36m(train_model pid=49044)\u001b[0m PR AUC scores for each fold: [0.12414050411462245, 0.12569785492280033, 0.1204515406591376]\n",
      "\u001b[36m(train_model pid=49044)\u001b[0m Average PR AUC: 0.12342996656552013\n",
      "\u001b[36m(train_model pid=49044)\u001b[0m F1 scores for each fold: [0.0, 0.0, 0.21492473348690203]\n",
      "\u001b[36m(train_model pid=49044)\u001b[0m Average F1 score: 0.07164157782896734\n",
      "\u001b[36m(train_model pid=49044)\u001b[0m Loss: 182355.28211975098\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=50022)\u001b[0m \n",
      "\u001b[36m(train_model pid=48912)\u001b[0m ROC AUC scores for each fold: [0.5002548716975874, 0.5001814313445272, 0.49982841455044613]\n",
      "\u001b[36m(train_model pid=48912)\u001b[0m Average ROC AUC: 0.5000882391975202\n",
      "\u001b[36m(train_model pid=48912)\u001b[0m PR AUC scores for each fold: [0.12330322714630051, 0.12036722320970455, 0.12576503060122404]\n",
      "\u001b[36m(train_model pid=48912)\u001b[0m Average PR AUC: 0.12314516031907637\n",
      "\u001b[36m(train_model pid=48912)\u001b[0m F1 scores for each fold: [0.0, 0.0, 0.0]\n",
      "\u001b[36m(train_model pid=48912)\u001b[0m Average F1 score: 0.0\n",
      "\u001b[36m(train_model pid=49713)\u001b[0m Loss: 25794.00566959381\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=50073)\u001b[0m \n",
      "\u001b[36m(train_model pid=49761)\u001b[0m Loss: 52383.171982274675\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=49623)\u001b[0m \n",
      "\u001b[36m(train_model pid=50022)\u001b[0m Loss: 25330.251924509932\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=49713)\u001b[0m Loss: 25793.750005722046\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=49761)\u001b[0m Loss: 64977.48402818639\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=49761)\u001b[0m \n",
      "\u001b[36m(train_model pid=49713)\u001b[0m \n",
      "\u001b[36m(train_model pid=49825)\u001b[0m \n",
      "\u001b[36m(train_model pid=49761)\u001b[0m Loss: 39663.63419077976\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=49909)\u001b[0m \n",
      "\u001b[36m(train_model pid=50073)\u001b[0m Loss: 25284.50297521514\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=49825)\u001b[0m Loss: 45961.98901761195\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=49510)\u001b[0m Loss: 779.331724435091\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=49761)\u001b[0m Loss: 25519.8972265076\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=49761)\u001b[0m Loss: 25493.675771230457\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=50022)\u001b[0m \n",
      "\u001b[36m(train_model pid=49510)\u001b[0m \n",
      "\u001b[36m(train_model pid=49510)\u001b[0m Loss: 44926.003954291344\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=50073)\u001b[0m \n",
      "\u001b[36m(train_model pid=49623)\u001b[0m \n",
      "\u001b[36m(train_model pid=49713)\u001b[0m Loss: 782.1257811263204\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=49825)\u001b[0m Loss: 25543.187636519182\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=49713)\u001b[0m Loss: 781.9321444407105\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=49761)\u001b[0m \n",
      "\u001b[36m(train_model pid=49825)\u001b[0m Loss: 30351.178696787396\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=49909)\u001b[0m \n",
      "\u001b[36m(train_model pid=50022)\u001b[0m Loss: 57198.51423555897\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=49713)\u001b[0m \n",
      "\u001b[36m(train_model pid=49761)\u001b[0m Loss: 33438.82068808838\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=49825)\u001b[0m \n",
      "\u001b[36m(train_model pid=49761)\u001b[0m Loss: 92874.30550605113\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=49761)\u001b[0m Loss: 145780.33265078077\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=49510)\u001b[0m Loss: 36737.69337248804\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=50022)\u001b[0m \n",
      "\u001b[36m(train_model pid=49825)\u001b[0m Loss: 114563.8478599592\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=49510)\u001b[0m ROC AUC scores for each fold: [0.5001425647171428, 0.5000683900971139, 0.49972598986162486]\n",
      "\u001b[36m(train_model pid=49510)\u001b[0m Average ROC AUC: 0.49997898155862713\n",
      "\u001b[36m(train_model pid=49510)\u001b[0m PR AUC scores for each fold: [0.12258265128815071, 0.12271227122712271, 0.12408496339853595]\n",
      "\u001b[36m(train_model pid=49510)\u001b[0m Average PR AUC: 0.12312662863793644\n",
      "\u001b[36m(train_model pid=49510)\u001b[0m F1 scores for each fold: [0.0, 0.0, 0.0]\n",
      "\u001b[36m(train_model pid=49510)\u001b[0m Average F1 score: 0.0\n",
      "\u001b[36m(train_model pid=49825)\u001b[0m Loss: 25637.603491566384\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=50447)\u001b[0m \n",
      "\u001b[36m(train_model pid=49623)\u001b[0m ROC AUC scores for each fold: [0.4996249987380729, 0.4997909048569488, 0.5001816854954726]\n",
      "\u001b[36m(train_model pid=49623)\u001b[0m Average ROC AUC: 0.4998658630301647\n",
      "\u001b[36m(train_model pid=49623)\u001b[0m PR AUC scores for each fold: [0.12259915179724865, 0.12634064076035237, 0.12025467525447645]\n",
      "\u001b[36m(train_model pid=49623)\u001b[0m Average PR AUC: 0.1230648226040258\n",
      "\u001b[36m(train_model pid=49623)\u001b[0m F1 scores for each fold: [0.0, 0.0, 0.0]\n",
      "\u001b[36m(train_model pid=49623)\u001b[0m Average F1 score: 0.0\n",
      "\u001b[36m(train_model pid=50073)\u001b[0m \n",
      "\u001b[36m(train_model pid=50073)\u001b[0m Loss: 26505.373976172257\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=50515)\u001b[0m \n",
      "\u001b[36m(train_model pid=49761)\u001b[0m Loss: 82092.14874501742\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=49761)\u001b[0m ROC AUC scores for each fold: [0.501072026724421, 0.4993282147917811, 0.49561931232771783]\n",
      "\u001b[36m(train_model pid=49761)\u001b[0m Average ROC AUC: 0.49867318461464\n",
      "\u001b[36m(train_model pid=49761)\u001b[0m PR AUC scores for each fold: [0.1252128648015298, 0.12297877649958847, 0.12119000418353806]\n",
      "\u001b[36m(train_model pid=49761)\u001b[0m Average PR AUC: 0.12312721516155212\n",
      "\u001b[36m(train_model pid=49761)\u001b[0m F1 scores for each fold: [0.0, 0.0, 0.0]\n",
      "\u001b[36m(train_model pid=49761)\u001b[0m Average F1 score: 0.0\n",
      "\u001b[36m(train_model pid=50073)\u001b[0m Loss: 25820.061506675607\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=50604)\u001b[0m \n",
      "\u001b[36m(train_model pid=49909)\u001b[0m ROC AUC scores for each fold: [0.500034302963776, 0.5, 0.4998696109129911]\n",
      "\u001b[36m(train_model pid=49909)\u001b[0m Average ROC AUC: 0.4999679712922558\n",
      "\u001b[36m(train_model pid=49909)\u001b[0m PR AUC scores for each fold: [0.12546501860074402, 0.12149757004859903, 0.12232852593436089]\n",
      "\u001b[36m(train_model pid=49909)\u001b[0m Average PR AUC: 0.12309703819456798\n",
      "\u001b[36m(train_model pid=49909)\u001b[0m F1 scores for each fold: [0.0, 0.0, 0.0]\n",
      "\u001b[36m(train_model pid=49909)\u001b[0m Average F1 score: 0.0\n",
      "\u001b[36m(train_model pid=50447)\u001b[0m Loss: 25393.75000431583\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=50660)\u001b[0m \n",
      "\u001b[36m(train_model pid=50447)\u001b[0m Loss: 25393.75\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=49713)\u001b[0m ROC AUC scores for each fold: [0.49996585165960933, 0.5, 0.5002026004487979]\n",
      "\u001b[36m(train_model pid=49713)\u001b[0m Average ROC AUC: 0.5000561507028024\n",
      "\u001b[36m(train_model pid=49713)\u001b[0m PR AUC scores for each fold: [0.12149757004859903, 0.12108484339373575, 0.12678202862711666]\n",
      "\u001b[36m(train_model pid=49713)\u001b[0m Average PR AUC: 0.12312148068981714\n",
      "\u001b[36m(train_model pid=49713)\u001b[0m F1 scores for each fold: [0.0, 0.0, 0.0]\n",
      "\u001b[36m(train_model pid=49713)\u001b[0m Average F1 score: 0.0\n",
      "\u001b[36m(train_model pid=50022)\u001b[0m Loss: 170220.1553205233\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=50749)\u001b[0m \n",
      "\u001b[36m(train_model pid=49825)\u001b[0m ROC AUC scores for each fold: [0.49914534787952514, 0.4990535226521147, 0.5001857416225715]\n",
      "\u001b[36m(train_model pid=49825)\u001b[0m Average ROC AUC: 0.4994615373847371\n",
      "\u001b[36m(train_model pid=49825)\u001b[0m PR AUC scores for each fold: [0.12305671357242455, 0.12309302178057327, 0.1232119291717185]\n",
      "\u001b[36m(train_model pid=49825)\u001b[0m Average PR AUC: 0.1231205548415721\n",
      "\u001b[36m(train_model pid=49825)\u001b[0m F1 scores for each fold: [0.0, 0.21958647219105626, 0.0]\n",
      "\u001b[36m(train_model pid=49825)\u001b[0m Average F1 score: 0.07319549073035209\n",
      "\u001b[36m(train_model pid=50809)\u001b[0m \n",
      "\u001b[36m(train_model pid=50515)\u001b[0m Loss: 777.9211579561234\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=50022)\u001b[0m Loss: 68908.82007882863\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=50073)\u001b[0m Loss: 25820.492843588487\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=50022)\u001b[0m ROC AUC scores for each fold: [0.49927876151313566, 0.5015714303755149, 0.4999288964732651]\n",
      "\u001b[36m(train_model pid=50022)\u001b[0m Average ROC AUC: 0.5002596961206386\n",
      "\u001b[36m(train_model pid=50022)\u001b[0m PR AUC scores for each fold: [0.1253025501195577, 0.12404346050910858, 0.12094981426090222]\n",
      "\u001b[36m(train_model pid=50022)\u001b[0m Average PR AUC: 0.12343194162985617\n",
      "\u001b[36m(train_model pid=50022)\u001b[0m F1 scores for each fold: [0.0, 0.0, 0.21579651941097724]\n",
      "\u001b[36m(train_model pid=50022)\u001b[0m Average F1 score: 0.07193217313699242\n",
      "\u001b[36m(train_model pid=50515)\u001b[0m \n",
      "\u001b[36m(train_model pid=50913)\u001b[0m \n",
      "\u001b[36m(train_model pid=50604)\u001b[0m Loss: 25604.37455553184\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=50073)\u001b[0m ROC AUC scores for each fold: [0.49995725816822884, 0.4998806267960166, 0.5009968375860013]\n",
      "\u001b[36m(train_model pid=50073)\u001b[0m Average ROC AUC: 0.5002782408500822\n",
      "\u001b[36m(train_model pid=50073)\u001b[0m PR AUC scores for each fold: [0.12508788026879214, 0.12372224680262729, 0.12128416438996414]\n",
      "\u001b[36m(train_model pid=50073)\u001b[0m Average PR AUC: 0.12336476382046119\n",
      "\u001b[36m(train_model pid=50073)\u001b[0m F1 scores for each fold: [0.0, 0.0, 0.0]\n",
      "\u001b[36m(train_model pid=50073)\u001b[0m Average F1 score: 0.0\n",
      "\u001b[36m(train_model pid=50447)\u001b[0m \n",
      "\u001b[36m(train_model pid=50809)\u001b[0m Loss: 25333.55877320121\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=50988)\u001b[0m \n",
      "\u001b[36m(train_model pid=50749)\u001b[0m Loss: 776.7604833096266\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=50604)\u001b[0m \n",
      "\u001b[36m(train_model pid=50660)\u001b[0m \n",
      "\u001b[36m(train_model pid=50988)\u001b[0m Loss: 31951.173191917\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=50913)\u001b[0m Loss: 85255.85612253782\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=50604)\u001b[0m Loss: 36786.576178138224\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=50809)\u001b[0m \n",
      "\u001b[36m(train_model pid=50809)\u001b[0m Loss: 35042.547388764186\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=50809)\u001b[0m Loss: 25644.57335524992\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=50749)\u001b[0m \n",
      "\u001b[36m(train_model pid=50515)\u001b[0m \n",
      "\u001b[36m(train_model pid=50749)\u001b[0m Loss: 65051.47703180983\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=50515)\u001b[0m Loss: 24991.690983127417\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=50604)\u001b[0m Loss: 25508.55879930067\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=50988)\u001b[0m \n",
      "\u001b[36m(train_model pid=50913)\u001b[0m \n",
      "\u001b[36m(train_model pid=50809)\u001b[0m Loss: 25735.171715586697\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=50604)\u001b[0m \n",
      "\u001b[36m(train_model pid=50660)\u001b[0m \n",
      "\u001b[36m(train_model pid=50447)\u001b[0m Loss: 25589.331047174004\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=50447)\u001b[0m \n",
      "\u001b[36m(train_model pid=50809)\u001b[0m Loss: 25714.05229614122\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=50988)\u001b[0m Loss: 43331.351941036\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=50913)\u001b[0m Loss: 78470.67648272324\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=50809)\u001b[0m \n",
      "\u001b[36m(train_model pid=50604)\u001b[0m Loss: 25158.598562696112\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=50988)\u001b[0m Loss: 39487.0117526363\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=50515)\u001b[0m ROC AUC scores for each fold: [0.5004831160509731, 0.500239430838692, 0.49988934812618835]\n",
      "\u001b[36m(train_model pid=50515)\u001b[0m Average ROC AUC: 0.5002039650052845\n",
      "\u001b[36m(train_model pid=50515)\u001b[0m PR AUC scores for each fold: [0.1231018691424529, 0.12301134658101699, 0.1232210569004539]\n",
      "\u001b[36m(train_model pid=50515)\u001b[0m Average PR AUC: 0.1231114242079746\n",
      "\u001b[36m(train_model pid=50515)\u001b[0m F1 scores for each fold: [0.0, 0.0, 0.0]\n",
      "\u001b[36m(train_model pid=50515)\u001b[0m Average F1 score: 0.0\n",
      "\u001b[36m(train_model pid=50749)\u001b[0m \n",
      "\u001b[36m(train_model pid=50660)\u001b[0m Loss: 775.9851852655411\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=51282)\u001b[0m \n",
      "\u001b[36m(train_model pid=50604)\u001b[0m Loss: 58991.51019965638\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=50988)\u001b[0m \n",
      "\u001b[36m(train_model pid=50749)\u001b[0m Loss: 777.3264985382557\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=50660)\u001b[0m ROC AUC scores for each fold: [0.500239939672311, 0.5002975442310877, 0.500254897003723]\n",
      "\u001b[36m(train_model pid=50660)\u001b[0m Average ROC AUC: 0.5002641269690405\n",
      "\u001b[36m(train_model pid=50660)\u001b[0m PR AUC scores for each fold: [0.12484993997599039, 0.12036080522589886, 0.12411843847162149]\n",
      "\u001b[36m(train_model pid=50660)\u001b[0m Average PR AUC: 0.12310972789117025\n",
      "\u001b[36m(train_model pid=50660)\u001b[0m F1 scores for each fold: [0.0, 0.0, 0.0]\n",
      "\u001b[36m(train_model pid=50660)\u001b[0m Average F1 score: 0.0\n",
      "\u001b[36m(train_model pid=50988)\u001b[0m Loss: 24812.441551665688\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=51378)\u001b[0m \n",
      "\u001b[36m(train_model pid=50604)\u001b[0m ROC AUC scores for each fold: [0.5000699748850752, 0.49872303211454017, 0.499754266381037]\n",
      "\u001b[36m(train_model pid=50604)\u001b[0m Average ROC AUC: 0.4995157577935508\n",
      "\u001b[36m(train_model pid=50604)\u001b[0m PR AUC scores for each fold: [0.1206126980742193, 0.12401562267910916, 0.12496813979649812]\n",
      "\u001b[36m(train_model pid=50604)\u001b[0m Average PR AUC: 0.12319882018327553\n",
      "\u001b[36m(train_model pid=50604)\u001b[0m F1 scores for each fold: [0.21508260030036472, 0.0, 0.0]\n",
      "\u001b[36m(train_model pid=50604)\u001b[0m Average F1 score: 0.07169420010012158\n",
      "\u001b[36m(train_model pid=50913)\u001b[0m \n",
      "\u001b[36m(train_model pid=50447)\u001b[0m Loss: 2268.2351921349773\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=51378)\u001b[0m Loss: 25401.195432878896\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=50447)\u001b[0m ROC AUC scores for each fold: [0.5001020320075573, 0.4997296623965687, 0.5000237758472266]\n",
      "\u001b[36m(train_model pid=50447)\u001b[0m Average ROC AUC: 0.4999518234171176\n",
      "\u001b[36m(train_model pid=50447)\u001b[0m PR AUC scores for each fold: [0.12549698288330882, 0.1233299594708495, 0.12042986481205956]\n",
      "\u001b[36m(train_model pid=50447)\u001b[0m Average PR AUC: 0.12308560238873929\n",
      "\u001b[36m(train_model pid=50447)\u001b[0m F1 scores for each fold: [0.0, 0.0, 0.0]\n",
      "\u001b[36m(train_model pid=50447)\u001b[0m Average F1 score: 0.0\n",
      "\u001b[36m(train_model pid=50913)\u001b[0m Loss: 91904.56192503407\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=50809)\u001b[0m ROC AUC scores for each fold: [0.5001028806584362, 0.5000247533626452, 0.5000684275352403]\n",
      "\u001b[36m(train_model pid=50809)\u001b[0m Average ROC AUC: 0.5000653538521073\n",
      "\u001b[36m(train_model pid=50809)\u001b[0m PR AUC scores for each fold: [0.12524003840614498, 0.12084285367133575, 0.12316926770708284]\n",
      "\u001b[36m(train_model pid=50809)\u001b[0m Average PR AUC: 0.1230840532615212\n",
      "\u001b[36m(train_model pid=50809)\u001b[0m F1 scores for each fold: [0.0, 0.215593873835279, 0.0]\n",
      "\u001b[36m(train_model pid=50809)\u001b[0m Average F1 score: 0.07186462461175967\n",
      "\u001b[36m(train_model pid=50913)\u001b[0m Loss: 25486.360929789622\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=51282)\u001b[0m Loss: 49279.71356994803\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=50749)\u001b[0m ROC AUC scores for each fold: [0.49996576046017943, 0.5000751573346197, 0.49974778748099086]\n",
      "\u001b[36m(train_model pid=50749)\u001b[0m Average ROC AUC: 0.4999295684252633\n",
      "\u001b[36m(train_model pid=50749)\u001b[0m PR AUC scores for each fold: [0.12383752324953501, 0.12216350360646501, 0.12335047997387372]\n",
      "\u001b[36m(train_model pid=50749)\u001b[0m Average PR AUC: 0.12311716894329124\n",
      "\u001b[36m(train_model pid=50749)\u001b[0m F1 scores for each fold: [0.0, 0.0, 0.0]\n",
      "\u001b[36m(train_model pid=50749)\u001b[0m Average F1 score: 0.0\n",
      "\u001b[36m(train_model pid=51282)\u001b[0m \n",
      "\u001b[36m(train_model pid=51282)\u001b[0m Loss: 48647.61276167517\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=50988)\u001b[0m ROC AUC scores for each fold: [0.49947998706191105, 0.4978811975626348, 0.4977683556389883]\n",
      "\u001b[36m(train_model pid=50988)\u001b[0m Average ROC AUC: 0.498376513421178\n",
      "\u001b[36m(train_model pid=50988)\u001b[0m PR AUC scores for each fold: [0.12315192114719313, 0.12412153234699391, 0.12123306475784644]\n",
      "\u001b[36m(train_model pid=50988)\u001b[0m Average PR AUC: 0.12283550608401117\n",
      "\u001b[36m(train_model pid=50988)\u001b[0m F1 scores for each fold: [0.0, 0.0009560229445506692, 0.0]\n",
      "\u001b[36m(train_model pid=50988)\u001b[0m Average F1 score: 0.00031867431485022306\n",
      "\u001b[36m(train_model pid=51282)\u001b[0m Loss: 24947.369949362826\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=51282)\u001b[0m Loss: 24955.407585806806\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=51378)\u001b[0m \n",
      "\u001b[36m(train_model pid=50913)\u001b[0m ROC AUC scores for each fold: [0.500099981446947, 0.5004001038048782, 0.5000684931506849]\n",
      "\u001b[36m(train_model pid=50913)\u001b[0m Average ROC AUC: 0.5001895261341701\n",
      "\u001b[36m(train_model pid=50913)\u001b[0m PR AUC scores for each fold: [0.12385925939657323, 0.12165069847391981, 0.12398727720098422]\n",
      "\u001b[36m(train_model pid=50913)\u001b[0m Average PR AUC: 0.12316574502382575\n",
      "\u001b[36m(train_model pid=50913)\u001b[0m F1 scores for each fold: [0.0, 0.0, 0.0]\n",
      "\u001b[36m(train_model pid=50913)\u001b[0m Average F1 score: 0.0\n",
      "\u001b[36m(train_model pid=51282)\u001b[0m Loss: 25086.634000989103\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=51282)\u001b[0m Loss: 25055.740387788865\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=51282)\u001b[0m Loss: 25028.587900068454\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=51282)\u001b[0m Loss: 25336.398915323585\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=51282)\u001b[0m \n",
      "\u001b[36m(train_model pid=51282)\u001b[0m Loss: 25443.65070595663\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=51282)\u001b[0m Loss: 25461.694643692626\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=51378)\u001b[0m Loss: 2839.3676061156275\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=51378)\u001b[0m \n",
      "\u001b[36m(train_model pid=51282)\u001b[0m Loss: 110720.31870057713\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=51378)\u001b[0m Loss: 26076.10865389032\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=51282)\u001b[0m ROC AUC scores for each fold: [0.49754213383245643, 0.49991406780770814, 0.4997495219010871]\n",
      "\u001b[36m(train_model pid=51282)\u001b[0m Average ROC AUC: 0.4990685745137506\n",
      "\u001b[36m(train_model pid=51282)\u001b[0m PR AUC scores for each fold: [0.12025793752942342, 0.12701099770052968, 0.12205604757340631]\n",
      "\u001b[36m(train_model pid=51282)\u001b[0m Average PR AUC: 0.1231083276011198\n",
      "\u001b[36m(train_model pid=51282)\u001b[0m F1 scores for each fold: [0.0, 0.0, 0.0]\n",
      "\u001b[36m(train_model pid=51282)\u001b[0m Average F1 score: 0.0\n",
      "\u001b[36m(train_model pid=51378)\u001b[0m Loss: 26058.12107884828\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=51378)\u001b[0m Loss: 26064.900873452145\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=51378)\u001b[0m Loss: 68050.62476291966\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=51378)\u001b[0m Loss: 26163.64770963802\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=51378)\u001b[0m Loss: 26126.733212975934\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=51378)\u001b[0m ROC AUC scores for each fold: [0.4999624318009965, 0.5000687568756876, 0.5001476020210537]\n",
      "\u001b[36m(train_model pid=51378)\u001b[0m Average ROC AUC: 0.500059596899246\n",
      "\u001b[36m(train_model pid=51378)\u001b[0m PR AUC scores for each fold: [0.12348422294649025, 0.12741567638938903, 0.11832512249132303]\n",
      "\u001b[36m(train_model pid=51378)\u001b[0m Average PR AUC: 0.12307500727573412\n",
      "\u001b[36m(train_model pid=51378)\u001b[0m F1 scores for each fold: [0.0, 0.0, 0.0]\n",
      "\u001b[36m(train_model pid=51378)\u001b[0m Average F1 score: 0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th style=\"text-align: right;\">   f1_score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_247ab_00000</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00001</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00002</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00003</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00004</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00005</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00006</td><td style=\"text-align: right;\">0.0741847  </td></tr>\n",
       "<tr><td>train_model_247ab_00007</td><td style=\"text-align: right;\">0.000969932</td></tr>\n",
       "<tr><td>train_model_247ab_00008</td><td style=\"text-align: right;\">0.0741452  </td></tr>\n",
       "<tr><td>train_model_247ab_00009</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00010</td><td style=\"text-align: right;\">0.074161   </td></tr>\n",
       "<tr><td>train_model_247ab_00011</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00012</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00013</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00014</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00015</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00016</td><td style=\"text-align: right;\">0.0757842  </td></tr>\n",
       "<tr><td>train_model_247ab_00017</td><td style=\"text-align: right;\">0.0739278  </td></tr>\n",
       "<tr><td>train_model_247ab_00018</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00019</td><td style=\"text-align: right;\">0.0736194  </td></tr>\n",
       "<tr><td>train_model_247ab_00020</td><td style=\"text-align: right;\">0.0731164  </td></tr>\n",
       "<tr><td>train_model_247ab_00021</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00022</td><td style=\"text-align: right;\">0.000327279</td></tr>\n",
       "<tr><td>train_model_247ab_00023</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00024</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00025</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00026</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00027</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00028</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00029</td><td style=\"text-align: right;\">0.0716416  </td></tr>\n",
       "<tr><td>train_model_247ab_00030</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00031</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00032</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00033</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00034</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00035</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00036</td><td style=\"text-align: right;\">0.0731955  </td></tr>\n",
       "<tr><td>train_model_247ab_00037</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00038</td><td style=\"text-align: right;\">0.0719322  </td></tr>\n",
       "<tr><td>train_model_247ab_00039</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00040</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00041</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00042</td><td style=\"text-align: right;\">0.0716942  </td></tr>\n",
       "<tr><td>train_model_247ab_00043</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00044</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00045</td><td style=\"text-align: right;\">0.0718646  </td></tr>\n",
       "<tr><td>train_model_247ab_00046</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00047</td><td style=\"text-align: right;\">0.000318674</td></tr>\n",
       "<tr><td>train_model_247ab_00048</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "<tr><td>train_model_247ab_00049</td><td style=\"text-align: right;\">0          </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-30 12:37:09,803\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/root/ray_results/train_model_2024-09-30_12-18-46' in 0.0112s.\n",
      "2024-09-30 12:37:09,824\tINFO tune.py:1041 -- Total run time: 1102.90 seconds (1102.85 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best config: {'units_1': 127, 'units_2': 118, 'learning_rate': 0.00018706814905236274}\n",
      "Best F1 Score: 0.07578417291699914\n",
      "\u001b[36m(train_model pid=51378)\u001b[0m Loss: 26110.36237318618\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def train_dnn(config):\n",
    "    X = ray.get(X_id)\n",
    "    y = ray.get(y_id)\n",
    "    _, _, f1 = evaluate_network(X, y, lr=config[\"learning_rate\"], layer_sizes=[config[\"units_1\"], config[\"units_1\"]])\n",
    "    return {\"f1_score\": f1}\n",
    "\n",
    "\n",
    "def train_model(config):\n",
    "    return train_dnn(config)\n",
    "\n",
    "\n",
    "search_space = {\n",
    "    # DNN hyperparameters\n",
    "    \"units_1\": tune.randint(16, 128),\n",
    "    \"units_2\": tune.randint(16, 128),\n",
    "    \"learning_rate\": tune.loguniform(1e-4, 1e-2)\n",
    "}\n",
    "\n",
    "ray.init(num_cpus=8, num_gpus=1, ignore_reinit_error=True)\n",
    "\n",
    "analysis = tune.run(train_model,\n",
    "                    config=search_space,\n",
    "                    num_samples=50,\n",
    "                    search_alg=BayesOptSearch(metric=\"f1_score\", mode=\"max\"),\n",
    "                    scheduler=ASHAScheduler(metric=\"f1_score\", mode=\"max\"),\n",
    "                    resources_per_trial={\n",
    "                        \"cpu\": 1,\n",
    "                        \"gpu\": 1/8\n",
    "                    })\n",
    "\n",
    "best_config = analysis.get_best_config(metric=\"f1_score\", mode=\"max\")\n",
    "best_trial = analysis.get_best_trial(metric=\"f1_score\", mode=\"max\")\n",
    "\n",
    "print(\"Best config:\", best_config)\n",
    "print(\"Best F1 Score:\", best_trial.last_result[\"f1_score\"])\n",
    "\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.available.res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
